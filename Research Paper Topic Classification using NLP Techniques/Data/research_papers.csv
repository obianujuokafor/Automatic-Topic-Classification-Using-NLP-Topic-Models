Id,Reference,Authors,Title,Year,Conference/ Journal,Codes,Abstract,Conclusion
1," Ludi, S., & Spencer, M. (2017). Design Considerations to Increase Block-based Language Accessibility for Blind Programmers Via Blockly. Journal of Visual Languages and Sentient Systems, 3(1), 119-124.","Ludi, S., & Spencer, M.",Design Considerations to Increase Block-based Language Accessibility for Blind Programmers Via Blockly.,2017,  Journal of Visual Languages and Sentient Systems.,"BBL, DES, SR, KN, CE, CN, DT, CC","Block-based programming languages are a popular means to introduce novices, specifically children, to programming and computational thinking concepts. They are tools to broaden participation in computing. At the same time, block-based languages and environments are an obstacle in broadening participation for many users with disabilities. In particular, block-based programming environments are not accessible to users who are visually impaired. This lack of access impacts students who are participating in computing outreach, in the classroom, or in informal settings that foster interest in computing. This paper will discuss accessibility design issues in block-based programming environments, with a focus on the programming workflow. Using Googles Blockly as a model, an accessible programming workflow is presented that works alongside the conventional mouse-driven workflow typical of block-based programming bbp. The project presented is still in progress.","The initial version of accessible Blockly should becompleted during Winter 2017. The results of a prior audio feedback study provided early feedback on the user interface, as well as assessed the impact of various types of audio feedback modalities for code navigation and the understanding of nesting. The feedback will be used in implementing code-based audio feedback during code navigation, in conjunction with the option for screen reader use, if needed. The accessibility features will also be studied in order to compare the usability impact for users with and without sight in order to ascertain what value may be found for sighted users as well as those who are visually impaired. Concerns include the verbosity of the information being presented, as well as the issues that young users may have as they are often users of Block-based systems. The formal studies will allow the team to refine the system and provide greater access for users, while providing a model for developers of other Blockly-based systems or block-based systems in general. In addition to block-based languages bbl, hybrid text and block-based languages bbl such as Pencil Code [11] also have the potential for increased accessibility. Our team is also looking at applying our strategies to Pencil Code, but the teams behind Pencil Code, Code.orgs App Lab, and other block languages can integrate accessibility into their systems designs by following the ideas we have discussed here. Some changes are at the user interface level while other accommodations are deeper in terms of new or redesigned features. An example of this is the Stride frame-based editor used in tools such asGreenfoot [12]. This editor enables users to work withoperations and constructs at an abstract level. This innovation,and others like it, may help increase access to computer science for students with disabilities, as well as students overall."
2,"Ludi, S., Simpson, J., & Merchant, W. (2016, October). Exploration of the use of auditory cues in code comprehension and navigation for individuals with visual impairments in a visual programming environment. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility (pp. 279-280). ACM.","Ludi, S., Simpson, J., & Merchant, W.",Exploration of the use of auditory cues in code comprehension and navigation for individuals with visual impairments in a visual programming environment. ,2016,"ACM SIGACCESS Conference on Computers and Accessibility, ACM.","AP, CN, CC, BBL, DES, DT, ACUE, SM","Visual programming languages are commonplace in engaging novice programmers. Accessibility challenges persist in these systems. This study investigates whether auditory cues improves a visually impaired programmer's ability to navigate and understand source code in a block-based language. The type of auditory cue that best serves this purpose is also investigated. The participants comprehension of source code using three trials withtwo tests each is presented, with each trial corresponding to a different form of audio cue. Participants are graded on how accurate their written source code is in comparison to the actualsource code.",
3,"Ludi, S. (2015, October). Position paper: Towards making block-based programming accessible for blind users. In 2015 IEEE Blocks and Beyond Workshop (Blocks and Beyond) (pp. 67-69). IEEE.","Ludi, S.",Towards making block-based programming accessible for blind users. ,2015, IEEE Blocks and Beyond Workshop. IEEE.,"BBL, DES, DT, WAPP, PC","Block-based programming environments are not accessible to users who are visually impaired. The lack of access impacts students who are participating in computing outreach, in the classroom, or in informal settings that foster interest in computing. This paper will discuss accessibility design issues in block-based programming bbp environments, as well as presentresearch questions and current design revisions beingundertaken in Blockly.",
4,"Milne, L. R., & Ladner, R. E. (2018, April). Blocks4All: overcoming accessibility barriers to blocks programming for children with visual impairments. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (p. 69). ACM.","Milne, L. R., & Ladner, R. E.","Blocks4All: overcoming accessibility barriers to blocks programming for children with visual impairments. ",2018,"CHI Conference on Human Factors in Computing Systems. ACM.","BBL, CH, CN, CC, SR, TS, SM, KDG, MSH","projects for pre-reader through grade 5 on the Hour of Code Blocks-based programming environments are a popular tool website use blocks-based environments [27]. to teach children to program, but they rely heavily on visual metaphors and are therefore not fully accessible for children with visual impairments. We evaluated existing blocks- based environments and identified five major accessibility barriers for visually impaired users. We explored techniques to overcome these barriers in an interview with a teacher of the visually impaired and formative studies on a touchscreen blocks-based environment with five children Unfortunately, these environments rely heavily on visual metaphors, which renders them not fully accessible for students with visual impairments. As these students are already underrepresented and must overcome a number of barriers to study computer science [17,21], it is important that they have equal access to curriculum in primary schools, at the start of the computer science pipeline. with visual impairments. We distill our findings on usable touchscreen interactions into guidelines for designers of blocks-based environments","We conducted an evaluation of current blocks-based environments and found five accessibility barriers. We designed multiple techniques to overcome these barriers and conducted a formative study to evaluate these techniques with five children with visual impairments. We distilled the findings from this study into a final design, which we plan to evaluate formally, and a set of design guidelines for designers of these applications."
5,"Caraco, L. B., Deibel, S., Ma, Y., & Milne, L. R. (2019, October). Making the Blockly Library Accessible via Touchscreen. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility (pp. 648-650). ACM.","Caraco, L. B., Deibel, S., Ma, Y., & Milne, L. R. ",Making the Blockly Library Accessible via Touchscreen.,2019,In The 21st International ACM SIGACCESS Conference on Computers and Accessibility. ACM.,"BBL, TS, SR, DES, CN, CE","Block-based programming environments are a popular way to learn programming. Many of these libraries, including Scratch and MITs App Inventor, are built on the Blockly library from Google. Unfortunately, programs built with the Blockly library are currently not accessible for people with visual impairments. We describe two designs to make the Blockly library accessible using a screen reader on a touchscreen device.",We present two interfaces which were designed to give the Blockly library inheritable accessible features to allow users to manipulate and read code swiftly. We plan to test these prototypes with students with visual impairments.
6,"Ong, J. S. Y., Amoah, N. A. O., Garrett-Engele, A. E., Page, M. I., McCarthy, K. R., & Milne, L. R. (2019, October). Expanding Blocks4All with Variables and Functions. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility (pp. 645-647). ACM.","Ong, J. S. Y., Amoah, N. A. O., Garrett-Engele, A. E., Page, M. I., McCarthy, K. R., & Milne, L. R. ", Expanding Blocks4All with Variables and Functions. ,2019,In The 21st International ACM SIGACCESS Conference on Computers and Accessibility. ACM.,"BBL,SR, TS, DES,  FUN, VAR","Blocks-based programming environments are often inaccessible for children with visual impairments who cannot interact with their visual components. We present our work on expanding Blocks4All, a touchscreen-based blocks-based programming environment that is accessible with screen readers, to improve its accessibility and expand its functionality. We describe our designs to support more complex functionality such as modifiable blocks, variables and functions and provide our code to encourage others to make their own environments accessible. We plan to evaluate the updated interface with children with low vision participating in a robotics competition","Our enhancements to Blocks4All have improved its accessibility for a larger audience of users with low-vision and motor impairments and have incorporated functionalities that enable users to create complex programs while teaching basic computing concepts, such as variables and functions. We plan to evaluate our changes to Blocks4All when it is used by a group of children with low vision in the upcoming WLRC. In the future, we also plan to thoroughly evaluate its accessibility with VoiceOver and Switch Control."
7,"Koushik, V., & Lewis, C. (2016, October). An Accessible Blocks Language: Work in Progress. In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility (pp. 317-318). ACM.","Koushik, V., & Lewis, C. .",An Accessible Blocks Language: Work in Progress. ,2016,In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility. ACM.,"BBL, KN, SR, NVP, PC, DT","Block languages are extensively used to introduce programming to children. They replace the complex and error prone syntax of textual languages with simple shape cues that show how program elements can be combined. In their present form, blind learnerscannot use them, because they rely on graphical presentation of code, and mouse interactions. We are working on a nonvisual blocks language called Pseudospatial Blocks (PB), that supportsprogram creation using keyboard commands with synthetic speech output. It replaces visual shape cues for language syntax, the key feature of block languages, with filtering of program elements by syntactic category.",
8,"Lewis, C. (2014). Work in Progress Report: Nonvisual Visual Programming. Psychology of Programming Interest Group.","Lewis, C.", Nonvisual Visual Programming. ,2014,Psychology of Programming Interest Group.,"NVP, DES, KN, DFP, AP, SPCH, PC","Visual programming systems are widely used to introduce children and other learners to programming, but they cannot be used by blind people. Inspired by the ideas of blind computer scientist T.V.Raman, the Noodle system provides nonvisual access to a dataflow programming system, a popular model for visual programming systems. This paper describes the design and implementation of Noodle and some of its capabilities. The paper suggests that the same approach used to develop Noodle could be applied to increase the accessibility of other visual programming systems for learners with disabilities. ","Nonvisual visual programming is possible, and offers potential benefits to learners who cannot see. Its development may also offer benefit to other users, as is common for work on inclusive design. "
9,"Schanzer, E., Bahram, S., & Krishnamurthi, S. (2019, February). Accessible AST-Based Programming for Visually-Impaired Programmers. In Proceedings of the 50th ACM Technical Symposium on Computer Science Education (pp. 773-779). ACM.","Schanzer, E., Bahram, S., & Krishnamurthi, S. ",Accessible AST-Based Programming for Visually-Impaired Programmers. ,2019, In Proceedings of the 50th ACM Technical Symposium on Computer Science Education. ACM.,"SR, CN, CC, KN, DES, SM, TBL, BBL, WAPP","Most programmers rely on visual tools (block-based editors, auto-indentation, bracket matching, syntax highlighting, etc.), which are inaccessible to visually-impaired programmers. While priorlanguage-specific, downloadable tools have demonstrated benefits for the visually-impaired, we lack language-independent, cloud-based tools, both of which are critically needed. We present a new toolkit for building fully-accessible, browser-based programming environments for multiple languages. Given a parser that meets certain specifications, this toolkit will generate a block editor familiar to sighted users that also communicates the structure of a program using spoken descriptions, and allows for navigation using standard (accessible) keyboard shortcuts. This paper presents the toolkit and a first evaluation of it. While the toolkit allows for full editing of code, we chose to focus strictly on navigation for this evaluation, using the navigation-only study design of Baker, Milne and Ladner. Visually-impaired programmers completed several tasks with and without our tool, and we compared their results and experience. Users had mproved accuracy when completing tasks, were significantly better able to orient when reading code, and felt better about completing the tasks when using the tool. Moreover, these improvements came with no significant change in task completion time over plain text, even for experienced programmers who navigate text using screen readers set to high words-per-minutes.","While this evaluation focused exclusively on using CMB to navigate code, future user studies will focus on the editing functionality. And given CMB's ability to let users manage their cognitive load (choosing when to work directly with syntax and when to avoid it), it would be useful to evaluate the tool when examining languages with which the users are already familiar. The user studies described here also provided extensive feedbackabout areas for future development. The simple searchfunctionality implemented for this study was clearly a limitation, and multiple users communicated that a more robust search feature would have been helpful when completing these tasks. Additionally, several users asked for a glances stack, which would allow them to hit a key and have their current position saved. After further exploration, they could hit a different key a quickly return to the location at the top of the stack.Finally, it would be valuable to explore the impact of using CMB as an IDE for sighted users. Having the computer read a description of a block in an age-appropriate language, or different natural language, could have major implications for all learners not justthose with visual impairments."
10,"J & K, M. (2014). Programming microworlds for visually impaired pupils. Futschek, G., Kynigos, C.: Constructionism and Creativity.","J & K, M. ", Programming microworlds for visually impaired pupils. ,2014,Constructionism and Creativity.,"TAN, AP, SPCH, SR, DES","The paper describes our research aimed at verification of the suitability of two programming environments for pupils of elementary schools with visual impairment. Our aim is to develop environments suitable for computer novices and usable for all the children  blind, partially sighted and without vision disorders. In addition, we designed a set of educational activities aimed at development of basic programming competences. For verification of the environments as well as the learning activities the design based research was used.","Our environments are physical micro-worlds [11] which help visually impaired learners train algorithmic thinking and help them understand the very basic algorithmic concepts. Besides the fact that children train their orientation in the space, they solve logic problems and make their first steps in environments similar to a programming environment. Our learning activities were suitable for our learners and we hope that they will be useful also for other teachers and their pupils (sightedand blind as well). The Lady Beetle environment and World of Sounds environment are not perfect.We did just the first step in development of appropriate universal programming environments available for children. We face a number of challenges. We still have not found a suitable way to introduce more complicated algorithmic concepts such as a conditional command, procedure, or variable. Our task in the near future will be to add these features to our environments and learningactivities."
11,"SՍnchez, J., & Aguayo, F. (2005, April). Blind learners programming through audio. In CHI'05 extended abstracts on Human factors in computing systems (pp. 1769-1772). ACM.","SՍnchez, J., & Aguayo, F. ",Blind learners programming through audio. ,2005,In CHI'05 extended abstracts on Human factors in computing systems. ACM.,"AP, DES, KN, CN, DT","The development of programming skills is a motivatingissue in computer science. Most programming languages are focused on sighted users. This study introduces APL, Audio Programming Language for blind learners. APL is based on audio interfaces to assist novice blind learners to develop problem solving and algorithmic thinking skills. APL was designed by and for blind learners to construct meaning by making programs. We tested APL with novice blind programmers during and after development. They tried, analyzed, and make improvements to APL. Learners wrote programs to solve problems with increasingly complexity. Our preliminary results evidence that audio programming languages such as APL can be constructed to fit the needs and mental models of blind learners to motivate and helpthem to enter to the programming world.","We have introduced APL, Audio Programming Languagefor blind learners. APL is designed to help novice blindlearners to enter to the programming world and to solveproblems and develop thinking skills by targeting theirneeds and mental models. Learners were able to interactand program APL by using audio-based commands. Theyunderstood programming concepts and apply them byprogramming their own ideas. Adequate uses of audio as a sensory interactive medium can help learners to learn how to program. We initially observed that blind learners can develop algorithmic and logic thinking skills with APL. They verbalized these skills, and wrote programs to prove their feasibility. The experience of interacting with APL was motivating and unique to them by expressing satisfaction with the programming experience. They have continued to program with APL after participating in the study. APL is not an alternative proposal to visual programming for blind users. We believe that for higher level tasks there should be interfaces to allow an adequate access to visual programming such as in [12]. Our proposal goes in a different direction. We aimed at motivating novice blind learners to learn programming basic ideas and solve problems with APL. We are learning the way blind users map the programming process by using APL. It may be somehow different from sighted users. Interacting through programming may have adifferent meaning to them. This should be studied morefully in future studies. Finally, APL is a first step to provide a robust Audio Programming Language to blind learners and thus helping them to enjoy programming and developing their cognition."
12,"SՍnchez, J., & Aguayo, F. (2006, July). APL: audio programming language for blind learners. In International Conference on Computers for Handicapped Persons (pp. 1334-1341). Springer, Berlin, Heidelberg.","SՍnchez, J., & Aguayo, F. ",APL: audio programming language for blind learners. ,2006,In International Conference on Computers for Handicapped Persons.,"AP, DES, KN, CN, DT","Programming skills are strongly emphasized in computer science. Programming languages are constructed based on sighted people as end-users. We have designed Audio Programming Language for blind learners based onaudio interfaces to support novice blind learners to develop and exercise problem solving skills. APL was designed with blind learners from the beginning toconstruct programs and solve problems with increasingly complexity. Audio Programming Language was usability tested during and after implementation. Blind learners used, wrote programs, and helped to make improvements to this programming language. Testing results evidence that APL mapped the mentalmodels of blind learners and helped to motivate them to write programs and thus entering to the programming field.","We have introduced APL, Audio Programming Language for blind learners. APL is  designed to help novice blind learners to enter to the programming world and to solveproblems and develop thinking skills by targeting their needs and mental models. Learners were able to interact and program APL by using audio-based commands.They understood programming concepts and apply them by programming their own ideas. Adequate uses of audio as a sensory interactive medium can help learners to learn how to program. We initially observed that blind learners can develop algorithmic and logic thinking skills with APL. They verbalized these skills, and wrote programs to prove their feasibility. The experience of interacting with APL was motivating and unique to them by expressing satisfaction with the programming experience. They have continued to program with APL after participating in the study. APL is not an alternative proposal to visual programming for blind users. We believe that for higher level tasks there should be interfaces to allow an adequate access to visual programming such as in [12]. Our proposal goes in a different direction. We aimed at motivating novice blind learners to learn programming basic APL: Audio Programming Language for Blind Learnersideas and solve problems with APL. Our idea is that their programs can be used by other people. To do this we have embedded in APL a Java code generator.We are learning the way blind users map the programming process by using APL. It may be somehow different from sighted users. Interacting through programming may have a different meaning to them. This should be studied more fully in futurestudies. Finally, APL is a first step to provide a robust Audio Programming Language to blind learners and thus helping them to enjoy programming and developing theircognition."
13,"D. B. Boardman, G. Greene, V. Khandelwal, and A. P. Mathur. Listen: A tool to investigate the use of sound for the analysis of program behavior. In Computer Software and Applications Conference, 1995. COMPSAC 95. Proceedings., Nineteenth Annual International, pages 184-189. IEEE, 1995.","D. B. Boardman, G. Greene, V. Khandelwal, and A. P. Mathur. ",Listen: A tool to investigate the use of sound for the analysis of program behavior.,1995," In Computer Software and Applications Conference, 1995. COMPSAC 95. ","ACUE, CD, PE","We describe the architecture and use of a toolnamed LISTEN. This as a general purpose tool to instrument computer programs so that during programexecution aspects of program behavior are mapped toaudible sound. Ongoing research aimed at investigating the usefulness of sound in various programming-related tasks and a lack of supporting tools led tothe development of LISTEN. This too1 is expected tofind use in tasks such as program testing and debugging, software-development environments for the visually handicapped, and data analysis using aural cues. We also report our initial experience gathered duringexpploraiory use of LISTEN and provide a summary ofongoing research using this tool.","We have described a system named LISTEN designed and prototyped to experiment with the use of sounds in understanding and analyzing run time behavior of computer programs. The system allows anexperimenter to specify a mapping of program relatedevents, activities, and variables to a large variet:y ofsound patterns. It is expected, and has been our initial experience, that such a mapping will allow the listener of a program to begin expecting certain soundsfrom the program. When one does not hear as perexpectations one begins to suspect some anomaly inthe code. Such a suspicion could be merely a misunderstanding on the part of the listener or could lead to the discovery of a program error. We believe the basic approach used in our work will be useful in the development of software systems that provide programauralization in addition to or as an alternative to thevisual method of displaying program behavior. In the case of a user with vision related disabilities, such analternative might be attractive. Further development of the LISTEN system is in progress. The focus of current work is to (a) develop a run time graphical interface for altering program sound mappings during program execution, (b) develop an auralized version of a debugging tool for use by blind users, and (c) explore the"
14,"Baker, C. M. (2017). Understanding and Improving Blind Students Access to Visual Information in Computer Science Education (Doctoral dissertation)","Baker, C. M.",Understanding and Improving Blind Students Access to Visual Information in Computer Science Education. ,2017,Doctoral dissertation,"CH, DES, CC, CN, TBP","Teaching people with disabilities tech skills empowers them to create solutions to problems theyencounter and prepares them for careers. However, computer science is typically taught in a highly visual manner which can present barriers for people who are blind. The goal of this dissertation is to understand and decrease those barriers. The first projects I present looked at the barriers that blind students face. I first present the results of my survey and interviews with blind students with degrees in computer science or related fields. This work highlighted the many barriers that these blind students faced. I then followed-up on one of the barriers mentioned, access to technology, by doing a preliminary accessibility evaluation of six popular integrated development environments (IDEs) and code editors. I found that half were unusable and all had some inaccessible portions. As access to visual information is a barrier in computer science education, I present three projects I have done to decrease this barrier. The first project is Tactile Graphics with a Voice (TGV). This project investigated an alternative to Braille labels for those who do not know Braille and showed that TGV was a potential alternative. The next project was StructJumper, which created a modified abstract syntax tree that blind programmers could use to navigate through code with their screen reader. The evaluation showed that users could navigate more quickly and easily determine the relationships of lines of code when they were using StructJumper compared to when they were not. Finally, I present a tool for dynamic graphs (the type with nodes and edges) which had two different modes for handling focus changes when moving between graphs. I found that the modes support different approaches for exploring the graphs and therefore preferences are mixed based on the users preferred approach. However, both modes had similar accuracy in completing the tasks. These projects are a first step towards the goal of making computer science education more accessible to blind students. By identifying the barriers that exist and creating solutions to overcome them, we can support increasing the number of blind students in computer science.","The overarching goal of my dissertation has been to support blind students in their pursuit oflearning computer science. Through the initial work I presented in Chapters 3 and 4, I have soughtto identify the barriers that we need to remove to increase the number of blind students in computerscience. Additionally, I sought to provide access to information that is not currently available.However, in my evaluations, I have realized that we need to aim to not just provide access to the materials, but we need to do so in a way that decreases the amount of information that we require blind students to hold in memory. In the evaluations of the tools I created, the amount information that blind students needed to hold in memory played a large role in determining thestudents experience and opinion of the tool. In the future, I aim to continue reducing the amount of information that blind students must be able to hold in their memory to successfully accessinformation."
15,"Weintrop, D., & Wilensky, U. (2015, June). To block or not to block, that is the question: students' perceptions of blocks-based programming. In Proceedings of the 14th International Conference on Interaction Design and Children (pp. 199-208). ACM.","Weintrop, D., & Wilensky, U. ","To block or not to block, that is the question: students' perceptions of blocks-based programming. ",2015,In Proceedings of the 14th International Conference on Interaction Design and Children (pp. 199-208). ACM.,"BBL, HSH, TBP, LAR"," Blocks-based programming tools are becoming increasingly common in high-school introductory computer science classes. Such contexts are quite different than the younger audience and informal settings where these tools are more often used. This paper reports findings from a study looking at how high school students view blocks-based programming tools, what they identify as contributing to the perceived ease-of-use of such tools, and what they see as the most salient differences between blocks- based and text-based programming. Students report that numerous factors contribute to making blocks-based programming easy, including the natural language description of blocks, the drag-and- drop composition interaction, and the ease of browsing the language. Students also identify drawbacks to blocks-based programming compared to the conventional text-based approach, including a perceived lack of authenticity and being less powerful. These findings, along with the identified differences between blocks-based and text-based programming, contribute to our understanding of the suitability of using such tools in formal high school settings and can be used to inform the design of new, and revision of existing, introductory programming tools. ","Blocks-based  programming  is  becoming  the  standard  way  to introduce  learners  to  programming  both  inside  classrooms  and beyond.  Educators  and  designers  advocate  for  this  approach arguing that  it  is easier  to  get  started  and more engaging  for  the learner.  In  this  paper, we  sought  to  understand  how  high  school students  enrolled  in  an  introductory  programming  course perceived  the  blocks-based  programming  approach.  Through cognitive interviews and surveys, we found that students generally found blocks-based programming to be easier than the text-based alternative, citing reasons including the natural language labels on the blocks, the shapes and colors of the blocks, the drag-and-drop composition  mechanism,  and  the  ease  of  browsing  the  blocks library.  Students  also  identified  drawbacks  to  the  blocks-based programming  approach,  including  issues  of  authenticity, expressive  power,  and  challenges  in  authoring  larger,  more sophisticated  programs.  We  also  found  that  the  differences  high school  students  see  between  blocks-based  and  text-based programming span the visual interface, the types of programs that can  be  authored,  as  well  a  different  programming  practices  that each representation supports. By analyzing student responses, we can  better  understand  how  the  learners  themselves  are  making sense of these introductory tools, isolate what they are identifying as  useful  about  the  environment  in  advancing  their  developing understanding, and use these insights to improve the tools we are currently  using  in  classrooms  and  inform  the  design  of  the  next generation of introductory programming environments. Our hope is that by doing so, we can better prepare today's students for the computational challenges of tomorrow."
16,"Potluri, V., Vaithilingam, P., Iyengar, S., Vidya, Y., Swaminathan, M., & Srinivasa, G. (2018). CodeTalk: Improving Programming Environment Accessibility for Visually Impaired Developers. CHI.","Potluri, V., Vaithilingam, P., Iyengar, S., Vidya, Y., Swaminathan, M., & Srinivasa, G. ",CodeTalk: Improving Programming Environment Accessibility for Visually Impaired Developers.,2018,CHI.,"CH, CD, DES, CC, CE, CN, KN, TBP, IDE, PRF, ACUE, SR, SM","In recent times, programming environments like VisualStudio are widely used to enhance programmer productivity. However, inadequate accessibility prevents Visually Impaired (VI) developers from taking full advantage of these environments. In this paper, we focus on the accessibility challenges faced by the VI developers in using Graphical User Interface (GUI) based programming environments. Based on a survey of VI developers and based on two of the authors personal experiences, we categorize the accessibility difficulties into Discoverability, Glanceability, Navigability, and Alertability. We propose solutions to some of these challenges and implement these in CodeTalk, a plugin for Visual Studio. We show how CodeTalk improves developer experience and share promising early feedback from VI developers who used our plugin.","We grouped the numerous accessibility challenges faced by Visually Impaired developers in using Graphic User Interface based programming environments into four categories, namely, discoverability, glanceability, navigability and alertability. We presented CodeTalk, a plugin for Visual Studio that enables Visually Impaired developers to overcome some of these challenges.Participants in the exploratory user study have given very positive feedback on the utility and potential of CodeTalk to improve accessibility. We also presented several possible research directions that emerge from this work."
17,"Stefik, A., Hundhausen, C.D., & Smith, D. (2011). On the design of an educational infrastructure for the blind and visually impaired in computer science. SIGCSE.","Stefik, A., Hundhausen, C.D., & Smith, D.", On the design of an educational infrastructure for the blind and visually impaired in computer science. ,2011, SIGCSE.,"DES, ACUE, HSH, MSH, CH, SR, IDE, AT, CE, CC, CD, KN","The blind and visually impaired community is significantly underrepresented in computer science. Students who wish to enter the discipline must overcome significant technological and educational barriers to succeed. In an attempt to help this population, we are engaged in a three-year research project to build an educational infrastructure for blind and visually impaired middle and high school students. Our primary research goal is to begin forging a multi-sensory educational infrastructure for the blind across the United States. We present here two preliminary results from this research: 1) a new auditory programming environment called Sod-beans, a programming language called Hop, and a multi-sensory (sound and touch) curriculum, and 2) an empirical study of our first summer workshop with the blind students. Results show that students reported a significant increase in programming self-efficacy after participating in our camp.","We are engaged in the first large-scale attempt to create a multi-sensory educational infrastructure for blind and visually impaired middle high schools students, starting with five schools for the blind throughout the U.S. We have made two primary contributions in this work: 1) an environment (Sod-beans), which includes auditory debuggers, a programming language (Hop), and a multi-sensory educational curriculum using tactile manipulatives, and 2) an empirical study of our first summer workshop working with the blind andvisually impaired students at the Washington State School for the Blind. We are our encouraged that, despite a small sample size and only a few days with our population, we were able to show a significant increase in programming self-efficacy, which, perhaps, could help inspire students from this community to consider learning more about computing. Over the next three years, we are expanding our program to include more schools for the blind, are making regular upgrades and expansions to our software, and are working with local and state governments to approve a multi-sensory curriculum that can be put into practice."
18,"Hadwen-Bennett, A., Sentance,S.,  Morrison C. Making Programming Accessible to Learners with VisualImpairments: A Literature Review","Hadwen-Bennett, A., Sentance,S.,  Morrison C. ","Making Programming Accessible to Learners with VisualImpairments: A Literature Review",,A Literature Review,"AP, TBP, BBL, CN, TAN","Programming can be challenging to learn, and for visually impaired (VI) learners, there are numerous additional barriers to the learning process. Many modern programming environments are inaccessible to VI learners, being difficult or impossible to interface with using a screen reader. A review of the literature has identified a number of strategies that have been employed in the quest to make learning to program accessible to VI learners. These can be broadly divided into the following categories; auditory and haptic feedback, making text-based languages (TBLs) accessible, making block-based languages (BBLs) accessible and physical artefacts. A common theme among the literature is the difficulty VI learners have in gaining an understanding of the overall structure of theircode. Much of the research carried out in this space to date focuses on the evaluation of interventions aimed atVI high-school and undergraduate students, with limited attention given to the learning processes of VI learners.Additionally, the majority of the research deals with TBLs, this is despite the fact that most introductory programming courses for primary learners use BBLs. Therefore, further research is urgently needed toinvestigate potential strategies for introducing VI children in primary education to programming and the learning processes involved.","Much of the research carried out in this space to date focuses on the development of interventions and theirimpact on student perceptions and engagement, with limited attention given to the pedagogy of teachingprogramming to Visually Impaired learners. This is certainly an area that warrants further research.Currently the most popular languages for introductory programming in primary schools in the UK are block-based (The Royal Society, 2017), which are currently not accessible to Visually Impaired learners. Therefore, there is a need for further investigation into potential accessible alternatives to BBLs, PPLs are a promising candidate given their potential to enable learners to gain an understanding of the overall structure of their code."
19,"Albusays, K., Ludi, S., & Huenerfauth, M. (2017). Interviews and Observation of Blind Software Developers at Work to Understand Code Navigation Challenges. ASSETS.","Albusays, K., Ludi, S., & Huenerfauth, M. ",Interviews and Observation of Blind Software Developers at Work to Understand Code Navigation Challenges. ,2017,ASSETS.,"CH, CN, SR, AT, LAR, PRF, IDE, TBP, DT","Integrated Development Environments (IDEs) play an important role in the workflow of many software developers, e.g. providing syntactic highlighting or other navigation aids to support the creation of lengthy codebases. Unfortunately, such complex visual information is difficult to convey with current screen-reader technologies, thereby creating barriers for programmers who are blind, who are nevertheless using IDEs. To better understand their usage strategies and challenges, we conducted an exploratory study to investigate the issue of code navigation by developers who are blind. We observed 28 blind programmers using their preferred coding tool while they performed various programming activities, in particular while they navigated through complex codebases. Participants encountered many navigation difficulties when using their preferred coding software with assistive technologies (e.g., screen readers). During interviews, participants reported dissatisfaction with the accessibility of most IDEs due to the heavy use of visual abstractions. To compensate, participants used multiple input methods and workarounds to navigate through code comfortably and reduce complexity, but these approaches often reduced their speed and introduced mistakes, thereby reducing their efficiency as programmers. Our findings suggest an opportunity for researchers and the software industry to improve the accessibility and usability of code navigation for blind developers in IDEs","In this paper,  we presented our exploratory study aimed at understanding  code  navigation challenges encountered by blind programmers  when using various  development  tools. We illustrated and discussed our methodology for learning about code navigation  difficulties  from  our  participants:  blind software developers.  Our study offers a new perspective  into the use of common development  tools (e.g., Eclipse, NetBeans, etc.) alongside assistive technologies by developers  who are blind. Most previous studies  have based their findings on a  small number of participants [2, 11,  19].  Our results arose from observing and interviewing a much larger sample, and our findings highlight various code navigation difficulties based on different programming languages and tools. Our findings indicated that participants struggled to navigate through codebases using existing development software alongside assistive technologies (e.g., screen reader). Although accessibility tools provided  benefits, they failed to  give enough support for blind programmers to navigate through codebases  quickly and comfortably.  Since  navigation options in IDEs are restricted to sighted users, blind programmers prefer simpler editors  (e.g., Notepad,  Notepad++). Participants explained and demonstrated how  diverse programming environments,  in combination with assistive  technologies,  lead to various challenges, often because these IDEs were designed without accessibility in mind.  Most of our participants preferred to use a screen reader (despite its limitations) to write software code. Others found this difficult, and therefore, favored using a  braille display instead.  However, several of our participants indicated that they could not afford to purchase a braille display. While most IDEs were not fully accessible,  blind programmers still rely on them to accomplish their work. Moreover, some blind programmers may seek sighted help for various  reasons,  mostly to access content that  is not accessible  with  assistive technologies. Although some blind programmers seek sighted help, others prefer writing custom scripts to overcome many programming challenges. For example, several  blind programmers wrote  custom scripts to enhance navigation in indentation-based languages. Others wrote  scripts for each IDEs, mainly  to  access features difficult  to use with a screen reader.  There were some limitations of our study: First, we only explored navigation difficulties encountered by experienced developers, who were totally blind, actively engaged in programming either as a job or hobby, and used  assistive technologies to access the computer display (e.g., screen reader, braille display, or both). It was beyond our scope to study novice programmers or individuals with greater diversity in their visual acuity. A further investigation into such an important user group may reveal different findings. Secondly, while the qualitative design of this study allowed us to gather firsthand comments and experiences from our user group, and to discover new issues that arose, in future work, it may be important to follow up this study with a survey administered to a larger group of participants, to verify some of our findings. The navigation challenges identified in this study illustrate the need  for further research on improving the usability and accessibility  of  current IDEs. For example, participants showed interest in using a new forms of code navigation, e.g. using hierarchical navigation approaches. Participants also indicated a desire for  bookmarks (or tags) features  that would allow blind programmers to tag specific line of code and return to it later for further modification. They also expressed interest in scope and nesting level indicator, auditory additional feedback, and methods for conveying class relationships, which could make programming more accessible for these users.  Finally, while the participants in our study expressed interest in various technology interventions to address their needs, it would be necessary in future work to conduct formal evaluations of the efficacy of such technology in studies with blind developers.  In fact, we are specifically planning, in our future work, to explore some form of auditory feedback which could help convey important information while users are navigating through lengthy codebases.  Several participants expressed interest in this technology.  Participants also suggested that audio cues could be used in various other programming activities. We plan to conduct participatory design research  to understand how to best use auditory cues in a code navigation system.  In summary, the results of this study provide future accessibility researchers  a foundation for understanding the needs of blind programmers, which may support their work in creating  and evaluating new technologies to address those needs"
20,"Mealin, S., & Murphy-Hill, E.R. (2012). An exploratory study of blind software developers. 2012 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC), 71-74.","Mealin, S., & Murphy-Hill, E.R. ",An exploratory study of blind software developers. ,2012,"IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC), 71-74.","CH, CN, SM, PRF, IDE, CO, FI","As a research community, we currently know verylittle about the challenges faced by blind software developers. Without knowing what those challenges are, the community cannot effectively address these challenges. In this paper, we describe the first exploratory empirical study, where we conducted eight interviews with blind software developers to identify aspects of software development that are a challenge. Our results suggest that visually impaired software developers face challenges, for instance, when using screen readers to look up information when writing code. We discuss a variety of implications, including that blind software developers need additional support in discovering relevant software development tools.","In a series of interviews, we have explored the challenges faced by blind software developers. Some results were expected, such as the inaccessibility of IDEs, but others were not, such as the frequent use of out-of-context editing. We have discussed several implications, but future work is still needed to quantify the extent to which our conclusions generalize and to understand the causes of some of our observation. For example, interviewees hinted about some of the tasks that they may be especially skilled at because of their blindness, but it was apparent to us that interviewees had not spent a lot of time reflecting on what they themselves are good at. A different type of study may further illuminate this particular subject; for instance, observational studies or interviews with blind developers colleagues may help expose the unique skills that blind people bring to the software development process."
21,"Albusays, K., & Ludi, S. (2016). Eliciting Programming Challenges Faced by Developers with Visual Impairments: Exploratory Study. 2016 IEEE/ACM Cooperative and Human Aspects of Software Engineering (CHASE), 82-85.","Albusays, K., & Ludi, S. ",Eliciting Programming Challenges Faced by Developers with Visual Impairments: Exploratory Study. ,2016," IEEE/ACM Cooperative and Human Aspects of Software Engineering (CHASE), 82-85.","CH, LAR, CN, CD, AT, PRF, IDE","Without understanding the programming difficulties faced by developers with visual impairments, the research community cannot begin to work on effective solutions to overcome these potential problems. This paper will describe our initial empirically based study to identify the problems blind software developers face. We analyzed 69 survey responses with blind developers in an effort to identify the aspects that are indeed a challenge to software development. The results indicate a number of difficulties, workarounds, and basis requirements that will serve as domain and stakeholder understand.","In this work, we explored the challenges faced by developers who are blind. The goal was to understand the blind developers programming problems as well as their workarounds to overcome these challenges. Some of the results were expected such as the lack of accessibility in IDEs as well as the use of a screen reader. We were surprised to see that blind developers use text editors as preferred tools to write code. It is not clear whether blind developers are unaware of the variety of features offered within the IDEs or find them difficult to use. For example, some participants noted that Eclipse or Visual Studio were not accessible while other respondents did use these tools. We have discussed several implications, but further investigation is needed to determine what our conclusions can be generalized. For example, the survey analysis indicated thedifficulty of code navigation where blind developers find it hard to navigate quickly through large amounts of code. The participants did not express sufficient details to such a problem and to generate requirements. A further study is needed to illuminate this particular subject with a well-defined user profile. We aim to conduct observational and interview studies with blind developers in a remote setup (using Skype orGoogle Hangouts). Thus, the geographical distribution can be overcome while providing a representational sample of computer science students as well as professional software developers for the needed subject."
22,"Smith, A.C., Cook, J.S., Francioni, J.M., Hossain, A., Anwar, M.M., & Rahman, M.F. (2004). Nonvisual tool for navigating hierarchical structures. ACM SIGACCESS, 77-78, 133-139.","Smith, A.C., Cook, J.S., Francioni, J.M., Hossain, A., Anwar, M.M., & Rahman, M.F. ", Nonvisual tool for navigating hierarchical structures. ,2004,"ACM SIGACCESS, 77-78, 133-139.","CN, TL, IDE","The hierarchical structure of a program can be quite complex. As such, many Integrated Development Environments (IDEs) provide graphical representations of program structure at different levels of abstraction. Such representations are not very accessible to non-sighted programmers, as screen readers are not able toportray the underlying hierarchical structure of the information. In this paper, we define a set of requirements for an accessible tree navigation strategy. An implementation of this strategy was developed as a plug-in to the Eclipse IDE and was tested by twelve student programmers. The evaluation of the tool shows the strategy to be an efficient and effective way for a non-sighted programmer to navigate hierarchical structures.","The accessible tree navigation tool described in this paper provides an effective and efficient strategy for non-sighted users to navigate within hierarchical representations of information. The tool offers users an interface that is consistent with the logicalstructure of trees. As such, users are able to develop an accurate mental model of the tree and can therefore navigate successfully within both familiar and unfamiliar trees of various sizes. The tool also provides the user with an appropriate focus context tool. The context features let the user know where they are located in the tree, relative to the tree's overall structure. These features include giving the user location information about distance from the root, who the cousins are, and what the density of the subtree is, as well as providing a means for the user to change the context relative to a new anchor point. The strategy also includes focus features that let the user get detailed information about a specific node, including the parent, the number of children and siblings, and the past history of visiting the node. Future work will include extending the implementation to provide a mechanism for users to build their own trees. This will be particularly useful for non-sighted students in computer science who can then draw trees and manipulate them as a way to understand concepts such as binary search trees."
23,"Baker, C.M., Milne, L.R., & Ladner, R.E. (2015). StructJumper: A Tool to Help Blind Programmers Navigate and Understand the Structure of Code. CHI.","Baker, C.M., Milne, L.R., & Ladner, R.E. ",StructJumper: A Tool to Help Blind Programmers Navigate and Understand the Structure of Code.,2015, CHI.,"TBP, CN, CC, DT, SM, KN, IDE, SR","It can be difficult for a blind developer to understand and navigate through a large amount of code quickly, as they are unable to skim as easily as their sighted counterparts. To help blind developers overcome this problem, we present StructJumper, an Eclipse plugin that creates a hierarchical tree based on the nesting structure of a Java class. The programmer can use the TreeView to get an overview of the code structure of the class (including all the methods and control flow statements) and can quickly switch between the TreeView and the Text Editor to get an idea of where they are within the nested structure. To evaluate StructJumper, we had seven blind programmers complete three tasks with and without our tool. We found that the users thought they would use StructJumper and there was a trend that they were faster completing the tasks with StructJumper.","We created StructJumper, an Eclipse plugin that allows blind programmers to quickly navigate through the code and see the how specific statements are nested within the code. We ran a user study with seven blind programmers and found that there is a trend that the tool has an effect on the time it took users to complete the tasks. We also found that participants were positive about the tool and that they would be interested in continuing to use the tool. The participants found it quicker to navigate through the code and, thought that StructJumper provided valuable information about the conditionals that apply to a line of code. "
24,"Calder, M., Cohen, R. F., Lanzoni, J., Landry, N., & Skaff, J. (2007, June). Teaching data structures to students who are blind. In ACM SIGCSE Bulletin (Vol. 39, No. 3, pp. 87-90). ACM.","Calder, M., Cohen, R. F., Lanzoni, J., Landry, N., & Skaff, J. ",Teaching data structures to students who are blind. ,2007,"In ACM SIGCSE Bulletin (Vol. 39, No. 3, pp. 87-90). ACM.","ACUE, SPCH, DES",We present our work in assisting students who are blind to understand fundamental data structures. We have developed a system called PLUMB EXTRA3 (EXploring data structures using Audible Algorithm Animation) that conveys an algorithm animation using audio cues and synthesized speech. This extends our earlier work on presenting graphs to users who are blind.,
25,"Cohen, R. F., Fairley, A. V., Gerry, D., & Lima, G. R. (2005). Accessibility in introductory computer science. ACM SIGCSE Bulletin, 37(1), 17-21.","Cohen, R. F., Fairley, A. V., Gerry, D., & Lima, G. R.",Accessibility in introductory computer science. ,2005,"ACM SIGCSE Bulletin, 17-21.",TBP,"This paper describes our efforts to integrate software accessibility into the introductory Computer Science course curriculum. Accessibility is an important aspect ofmodern software systems for both legal and ethical reasons. The acceptance of Java as language for introductory Computer Science course gives us the opportunity to teach accessibility from the beginning, since Java Accessibility is simple and integrated into Swing components. We present simple guidelines on how to incorporate Accessibility into a Java based introductory Computer Science course, and describe programming projects that incorporateaccessibility.",
26,"Stefik, A., Hundhausen, C., & Patterson, R. (2011). An empirical investigation into the design of auditory cues to enhance computer program comprehension. International Journal of Human-Computer Studies, 69(12), 820-838.","Stefik, A., Hundhausen, C., & Patterson, R. ",An empirical investigation into the design of auditory cues to enhance computer program comprehension. ,2011,"International Journal of Human-Computer Studies, 69(12), 820-838.","CC, ACUE, CD, SR, IDE, LAR, COL","Decades of research have led to notable improvements in the representations used to aid human comprehension of computer programs. Much of this research has focused on visual representations, which leaves open the question of how best to design auditory representations of computer programs. While this question has particular relevance for visually impaired programmers, sighted programmers might also benefit from enhanced auditory representations of their programs. In order to investigate this question empirically, first, we introduce artifact encoding, a novel approach to rigorously measuring the comprehensibility of auditory representations of computer programs. Using this approach as a foundation, we present an experimental study that compared the comprehensibility of two alternative auditory program representations: one with lexical scoping cues that convey the nesting level of program statements, and another without such scoping cues. The results of our first experiment validate both artifact encoding and the scoping cues we used. To see whether auditory cues validated through our paradigm can aid program comprehension in a realistic task scenario, we experimentally compared programmers ability to debug programs using three alternative environments: (1) an auditory execution environment with our empirically derived auditory cues; (2) an auditory execution environment with the current state-of-the-art auditory cues generated by a screen reader running on top of Microsoft Visual Studio; and (3) a visual version of the execution environment. The results of our second experiment showed that our comprehensible auditory cues are significantly better than the state-of-the-art, affording human performance approaching theeffectiveness of visual representations within the statistical margin of error. This research contributes a novel methodology and foundational empirical data that can guide the design of effective auditory representations of computer programs.","This research makes three key contributions to theliterature on auditory programming. First, it furnishesa rigorous empirical methodology for measuring thecomprehension of computer programs, which we happened to apply to auditory processing a methodology that can form a foundation for future research in the field. Second, it provides empirical evidence validating that the artifact encoding approach can detect differences in the human comprehension of auditory cues. And third, it presents empirical evidence that we can create auditory representations that are significantly better than the state-of-the-art (an IDE coupled with a screen reader), and that approach the effectiveness of visual representations within the statistical margin of error. While the preliminary studies presented here focused on the performance of sighted individuals, an obvious next step for future research is to see if the results apply to non-sighted individuals, who have a greater stake in auditory representations of computer programs than sighted individuals. To that end, we recently ran a summer camp in which we performed a field test of the successor to SOD (Sodbeans) with 12 blind and visually impaired high school students. Sobeans includes the latest version of our narrated debugger, an in-place screen reader replacement (Sappy), and a custom computer programming language (Hop) designed specifically for this population through philosophically similar empirical studies. During this camp, we gathered significant data on how students interacted with Sodbeans in real programming tasks and we tested general usability issues (e.g., opening files using audio, creating projects, navigating windows). We are also designing a custom, 18-week, introductory programming curriculum, rooted in Sodbeans, that will be offered at several schools for the blind throughout the U.S. We look forward, in future publications, to reporting more detailed results regarding the effectiveness of tools designed using the methodology presented here in blind and visually impaired populations. Our hope is that these tools will ultimately empower the blind and visually impaired to write their own programming tools tools that are for the blind and by the blind."
27,"Armaly, A. (2016, May). An empirical study of blindness and program comprehension. In 2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C) (pp. 683-685). IEEE.","Armaly, A. ",An empirical study of blindness and program comprehension.,2016,In 2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C) (pp. 683-685). IEEE.,"CC, SR, PRF, SM, KN","Blind programmers typically use a screen reader when reading code whereas sighted programmers are able to skim the code with their eyes. This difference has the potential to impact the generalizability of software engineering studies and approaches. We present a summary of a paper which will soon be under review at TSE that investigates how code comprehension of blind programmers differs from that of sighted programmers. Put briefly, we found no statistically significant differences between the areas of code that theblind programmers found to be important and the areas of code that the sighted programmers found to be important.","In conclusion, we found that the blind and sighted pro-grammers both prioritized method signatures over other code areas. The blinded programmers did not prioritize any code areas over others. This suggests that the newly-introduced screen reader presented challenges for the blinded programmers but that the learning curve shrank as the programmer became more proficient with the screen reader. The similarities between the blind and sighted groups suggests that software engineering studies and productivity enhancing tools are applicable to blind as well as sighted programmers, provided that any newly-developed tools are accessible. We hope that these findings lay a foundation for future researchthat clarifies the question of how a blind person can be expected to integrate into a team of sighted programmers in the workplace."
28,"Baker, C. M. (2017). Increasing access to computer science for blind students. ACM SIGACCESS Accessibility and Computing, (117), 19-22.","Baker, C. M. ",Increasing access to computer science for blind students. ,2017,"ACM SIGACCESS Accessibility and Computing, (117), 19-22.","TBP, CN, CC, DT, SM, DS","Computer science has many aspects that are inaccessible to someone who is blind. My research has focused on identifying the different barriers that exist for blind students in computer science and creating technology to overcome them. I have done two projects towards this goal, StructJumper and a survey and interviews with blind students about their experiences learningprogramming. StructJumper is a tool that creates a tree based on the structure of the code, which can be used for navigation and discovering contextual information in the code. The surveys and interviews focused on the barriers that blind students faced in learning computer science. For my dissertation, I am proposing one more project investigating how to convey updates to datastructures.",
29,"Albusays, K. (2018). Exploring auditory cues to locate code errors and enhance navigation for developers who are blind. ACM SIGACCESS Accessibility and Computing, (120), 11-15.","Albusays, K. ",Exploring auditory cues to locate code errors and enhance navigation for developers who are blind. ,2018,"ACM SIGACCESS Accessibility and Computing, (120), 11-15.","ACUE, CD, CN ","The goal of my research is to support the workflow of programmers who are blind; prior work hasfound that these users face challenges in using screen-readers to locate errors and debug software code. Recent advancements in auditory cues have made them a potential candidate for providing useful feedback to both sighted and visually impaired users, but little known about the effectiveness and the usability of such cues for blind programmers. I propose to investigate theefficiency of two different auditory techniques, to locate code errors and reduce the amount of time required to navigate through lengthy codebases. I will compare learning rates for Earcons (hierarchical representations of musical tones) and Spearcons (compressed speech) as potential candidates for the auditory feedback system. My research aim is to understand the proper way toimplement usable auditory cues for these users. This document describes my research motivations, proposed research plan, current progress, and the potential contribution to the field of software engineering and accessibility for blind programmers.",
30,"Hutchinson, J., & Metatla, O. (2018, April). An Initial Investigation into Non-visual Code Structure Overview Through Speech, Non-speech and Spearcons. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems (p. LBW562). ACM.","Hutchinson, J., & Metatla, O. "," An Initial Investigation into Non-visual Code Structure Overview Through Speech, Non-speech and Spearcons. ",2018,In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems (p. LBW562). ACM.,"TBP, ACUE, DT, CC, SPCH, SM, PRF","We investigate a novel, non-visual approach to overviewing object-oriented source code and evaluate the efficiency of different categories of sounds for the purpose of getting an overview of source code structure for a visually-impaired computer programmer. A user-study with ten sighted and three non-sighted participants compared the effectiveness of speech, non-speech and spearcons on measures of accuracy and enjoyment for the task of quickly overviewing a class file. Results showed positive implications for the use of non-speech sounds in identifying programming constructs and for aesthetic value, although the effectiveness of the other sound categories in these measurements are not ruled out. Additionally, various design choices of the application impacted results, which should be of interest to designers of auditory display, accessibility and education.","We have made a preliminary case for non-speech soundsas a means of overviewing object-oriented source code.Our initial results show however, that the value of speech and spearcons cannot be ruled out. Furthermore, the small sample size, (particularly of non-sighted participants), the effect of the testing method on the measurement of speed and the fact that some of the design choices of the sounds were questioned by participants demonstrates that there is room for improvement in this work."
31,"Smith, A. C., Francioni, J. M., & Matzek, S. D. (2000, November). A Java programming tool for students with visual disabilities. In ACM SIGACCESS Conference on Assistive Technologies: Proceedings of the fourth international ACM conference on Assistive technologies (Vol. 13, No. 15, pp. 142-148).","Smith, A. C., Francioni, J. M., & Matzek, S. D. ", A Java programming tool for students with visual disabilities. ,2000,"In ACM SIGACCESS Conference on Assistive Technologies: Proceedings of the fourth international ACM conference on Assistive technologies (Vol. 13, No. 15, pp. 142-148).","KN, TBP, TL, CN, CC, SPCH, DT","This paper reports on a tool for assisting students withvisual disabilities in learning how to program. The tool ismeant to be used by computer science majors learning the programming language Java. As part of the developmental process of building this tool, we have implemented a rapid prototype to be used by people with disabilities in order to define appropriate requirements for the full version of the tool. This requires that the prototype is completely usable via a keyboard and speech interface, and it is easily adaptable for trying out different strategies. In this paper, we present the motivation and philosophy of the full tool, called JavaSpeak. We also present the details of a prototype implementation of JavaSpeak.","Our focus is on teaching students to learn how to program. Therefore, we started out with our understanding as teachers of how students learn to program. The information we want to present is related to what will help students learn the Java programming language as well as to help them develop the art/skill of programming. As such, we believe the tool can help students without visual disabilities as well."
32,"Stefik, A. (2008). On the design of program execution environments for non-sighted computer programmers (Doctoral dissertation, PhD thesis, Washington State University).","Stefik, A. ",On the design of program execution environments for non-sighted computer programmers.,2008,"Doctoral dissertation, PhD thesis.","DES, CC, CN, CD, ACUE, PE, TL , TBP,","Comprehending and debugging computer programs is difficult for sighted programmers. For the non-sighted, these tasks are even more difficult. Since non-sighted computer programmers have inherent physiological limitations, they must rely on auditory cues to represent the computer programs they are writing, modifying, exploring, or debugging. State-of-the-art interfaces for non-sighted programmers work by retrofitting screen readers onto existing development environments.As such, these environments are built with sighted usability in mind, but often pay little heed tothe needs of a community that cannot see the computer screen. In contrast, this research develops an approach to building tools for the non-sighted computer programmer from the ground up. The core of this ground up approach lies in the use of basic research and empirical studies to inform auditory cue design independently of visual environments. Basic research can, for example, tell us how well auditory cues can be understood, under what context they should be used, and when working memory is being over-taxed a typical problem with non-sighted interfaces in general. In this dissertation, I present a line of research related to non-sighted computer programmers. The primary contributions include a characterization of the design space of audio-based program execution environments, a novel empirical paradigm for analyzing the comprehension of auditory cues (artifact encoding), a research tool for exploring that design space (the Sonified Omniscient Debugger), and empirical evidence that building audio-based programming tools for thenon-sighted from the ground up is superior to retrofits of existing visual tools.","Non-sighted programmers face problems that their sighted counterparts do not. While the sightedcan look at multiple parts of the screen in parallel, where each component provides unique information (e.g., a watch window and a source window), the non-sighted use serial, speech-based, auditory cues that present one type of information at a time. Further, while the sighted can look at an integrated development environment and garner meta-information from the visuals (e.g., syntax highlighting, breakpoints, details of program execution), the non-sighted need to have meta-auditory cues inserted into the audio (e.g., auditory scoping cues, capitalization). Fundamentally, this thesis argues that we need to rethink our methodology for designing tools for the non-sighted. At the center of this problem is the need for a means of measuring the comprehension of auditory cues. By measuring comprehension we can determine what auditory cues will be easily understood (e.g., if true) and what other cues provide too little information to be useful (e.g., F9, F9, F9, F9). My methodology for measuring comprehension is artifact encoding. This method provides arich data set that is automatically analyzed and scored by the computer. I have demonstrated that non-sighted programming interfaces built in this way: from the ground up by way of careful auditory cue construction and through the use of comprehension measures, are ultimately superior to retrofitted screen readers. As this thesis has shown, the current state of the art for non-sighted interfaces is to retrofit accessibility on top of an existing interface, sometimes with little regard for usability. I argue that a paradigm shift for non-sighted interfaces is needed, where companies designing accessible products worry less about designing accessibility APIs screen readers can attach to and focus more on ensuring the audio is sensible. I have offered empirical evidence that making even minor adjustments to the auditory cues can significantly alter a human's comprehension of what those cues represent (see chapter 5), and changes in auditory cues can make a significant difference in the usability of a sound based interface (see chapter 7). This thesis promotes a bottom-up approach to accessibility. By working to create better programming environments for non-sighted programmers, we make it easier for these talented individuals to design technology for themselves (e.g. better screen readers that provide better auditory cues). However, the current state-of-the-art in programming environments for the non-sighted needs substantial improvement a problem which this work has begun to address."
33,"Morrison, C., Villar, N., Thieme, A., Ashktorab, Z., Taysom, E., Salandin, O., ... & Grayson, M. (2018). Torino: A tangible programming language inclusive of children with visual disabilities. Human Computer Interaction, 1-49.","Morrison, C., Villar, N., Thieme, A., Ashktorab, Z., Taysom, E., Salandin, O., ... & Grayson, M. ",Torino: A tangible programming language inclusive of children with visual disabilities. ,2018," Human Computer Interaction, 1-49.","TAN, DES, SM, SPCH","Across the world, policy initiatives are being developed to engage children with computer programming and computational thinking. Diversity and inclusion has been a strong force in this agenda, but children with disabilities have largely been omitted from theconversation. Currently, there are no age appropriate tools for teaching programming concepts and computational thinking to primary school children with visual disabilities.We address this gap through presenting the design and implementation of Torino, a tangible programming language for teaching programming concepts to children age 7-11 regardless of level of vision. In this paper, we: 1) describe the design process done in conjunction with children with visual disabilities; 2) articulate the design decisions made;and 3) report insights generated from an evaluation with 10 children with mixed visual abilities that considers how children are able to trace (read) and create (write) programs with Torino. We discuss key design trade-offs: 1) readability versus extensibility; and 2) size versus liveness. We conclude by reflecting upon how an inclusive design approach shaped the final result.","There is a strong diversity agenda behind the push to get more children fluent with computational thinking and able to use it for the benefit of society. This agenda hasmainly focused on gender and ethnicity, but disability is an important segment that should not be ignored. To this end, appropriate tools are needed to support learning. While efforts have been made for older blind students, there has been little attention to computing education for blind learners in early years and primary schooling. This is particularly problematic given the recent mandatory introduction of computing for theprimary school age group in several countries, including the UK. Torino aims to address this gap by providing a tangible language for teaching programming and computational thinking concepts to children ages 7 to 11 inclusive of those with visual disabilities. Having taken an inclusive design approach to the development of Torino we created a learning tool that is appropriate for use by children with visual disabilities without its design being exclusive to them. The development of a bead metaphor to provide a 3-dimensional experience that prioritises tactile interaction over visual understanding sets Torino apart from many tangible programming languages and interactive blocks available in the research literature, and on the market. Existing designs are all block shaped,relying on the metaphor of puzzle pieces. Working with children with visual disabilities in the Torino Young Design Team helped us reimagine this space and explore novel ways of interactions that would not rely on vision for interpretation. As a result, taking an inclusive design approach enabled us to innovate both in form and underlying technology."
34,"Morrison, C., Villar, N., Hadwen-Bennett, A., Regan, T., Cletheroe, D., Thieme, A., & Sentance, S. (2019). Physical Programming for Blind and Low Vision Children at Scale. Human Computer Interaction, 1-35.","Morrison, C., Villar, N., Hadwen-Bennett, A., Regan, T., Cletheroe, D., Thieme, A., & Sentance, S. ",Physical Programming for Blind and Low Vision Children at Scale. ,2019,"Human Computer Interaction, 1-35.","TAN, DES, PE, CO, LAR","There is a dearth of appropriate tools for young learners with mixed visual abilities to engage with computational learning. Addressing this gap, Torino is a physical programming language for teaching computational learning to children ages 7 to 11 regardless of level of vision. To create code, children connect physical instruction pods and tune their parameter dials to create music, audio stories, or poetry. Currently, theuptake of novel educational technologies to support inclusive education of children with disabilities continues to be limited at scale. We consider how the Torino Learning Environment supports non-specialist teachersto teach computational learning to children with mixed visual abilities in a UK-wide evaluation with 75 children and 30 teachers over a period of three months. We demonstrate how children can successfully learn witha novel physical programming language. We articulate how key design constructs such as persistent program overview and liveness supported non-specialist teachers to co-produce learning for children of different ages, visual and cognitive abilities. We conclude with reflective guidance on evaluating inclusive educational technologies at scale.","The technologies that we design play a mediating role in our interactions with the world (Verbeek, 2015). If we are to achieve an inclusive learning culture, we need to provide tools that embed this philosophy in the design and help transform existing practices. Careful design can go beyond an engaging experience to support non-specialist teachers to co-produce learning and eventually take ownership of the technology."
35,"Kane, S. K., Koushik, V., & Muehlbradt, A. (2018, June). Bonk: accessible programming for accessible audio games. In Proceedings of the 17th ACM Conference on Interaction Design and Children (pp. 132-142). ACM.","Kane, S. K., Koushik, V., & Muehlbradt, A.",Bonk: accessible programming for accessible audio games. ,2018,In Proceedings of the 17th ACM Conference on Interaction Design and Children (pp. 132-142). ACM.,"CH, DES, HSH, TBP, SR, SPCH, OUT, SM, PC, DT, WAPP, IDE","Introductory computer programming presents a number of challenges for blind and visually impaired screen reader users. In addition to the challenges of navigating complex code documents using a screen reader, novice programmers who are blind are often unable to experience fun coding projects such as programming games or animations. To address these accessibility barriers, we developed Bonk, an accessible programming environment that enables the creation of interactive audio games using a subset of the JavaScript program- ming language. Bonk enables novice programmers to create, share, play, and remix accessible audio games. In this paper, we introduce the Bonk programming toolkit and describe its use in a week-long programming workshop with blind and visually impaired high school students. Students in the workshop were able to create and share original audio games using Bonk, and expressed enthusiasm about furthering their programming knowledge.","We introduced Bonk, an accessible programming environment for creating accessible media. Bonk provides low barriers to entry for creating accessible audio games, and can enable aspiring programmers to develop their skills by creating, sharing, and remixing games that are built from the ground up to be accessible. A formative evaluation of Bonk with 10 blind and visually impaired high school students showed that this approach can enable students with a range of technical ability to create and share games, and that this accessible and collaborative programming environment can support shared creative work and play for people with a range of abilities"
36,"Thieme, A., Morrison, C., Villar, N., Grayson, M., & Lindley, S. (2017, June). Enabling collaboration in learning computer programing inclusive of children with vision impairments. In Proceedings of the 2017 Conference on Designing Interactive Systems (pp. 739-752). ACM.","Thieme, A., Morrison, C., Villar, N., Grayson, M., & Lindley, S. ",Enabling collaboration in learning computer programing inclusive of children with vision impairments. ,2017,In Proceedings of the 2017 Conference on Designing Interactive Systems (pp. 739-752). ACM.,"DES, TAN, SM, ACUE/OUT","We investigate how technology can support collaborative learning by children with mixed-visual abilities. Responding to a growing need for tools inclusive of children with vision impairments (VI) for the teaching of computer programing to novice learners, we explore Torino  a physical programing language for teaching programing constructs and computational thinking to children age 7 to 11. We draw insights from 12 learning sessions with Torino that involved five pairs of children with vision ranging from blindness to full-sight. Our findings show how sense-making of the technology, collaboration, and learning were enabled through an interplay of system design, programing tasks and social interactions, and how this differed between the pairs. The paper contributes insights on the role of touch, audio and visual representations in designs inclusive of people with VI, and discusses the importance and opportunities provided through the social in negotiations of accessibility, for learning, and for self-perceptions of ability and self-esteem.","We explored the design of the physical programing language Torino for enabling collaborative learning experiences for children with mixed-visual abilities. Our findings show how sense-making of the technology, collaboration, and learning were enabled through an interplay of system design, programing tasks and social interactions. They illustrate how identified mechanisms for gaining and keeping awareness of the program and partner came to matter differently between the learning pairs. We contributed insights to the role of touch, audio feedback and visual representations in designs inclusive of children with VI, and highlighted the importance and opportunities of the social for progress in learning, for creating shared languages and references outside of vision that can supporting accessibility and inclusion, and for self-perceptions of ability and self-esteem of children with VI."
37,"Koushik, V., Guinness, D., & Kane, S. K. (2019, April). StoryBlocks: A Tangible Programming Game To Create Accessible Audio Stories. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (p. 492). ACM.","Koushik, V., Guinness, D., & Kane, S. K. ",StoryBlocks: A Tangible Programming Game To Create Accessible Audio Stories.,2019, In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (p. 492). ACM.,"TAN, BBL, DES, LAR(16), OUT","Block-based programming languages can support novice programmers through features such as simplified code syntax and user-friendly libraries. However, most block- based programming languages are highly visual, which makes them inaccessible to blind and visually impaired students. To address the inaccessibility of block-based languages, we introduce StoryBlocks, a tangible block- based game that enables blind programmers to learn basic programming concepts by creating audio stories. In this paper, we document the design of StoryBlocks and report on a series of design activities with groups of teachers, Braille experts, and students. Participants in our design sessions worked together to create accessible stories, and their feedback offers insights for the future development of accessible, tangible programming tools.","As society increasingly recognizes the importance ofcomputer science education, we must continue to identify ways in which computer science education can exclude learners with disabilities. By identifying the core benefits of block-based languages and representing them in an accessible format, StoryBlocks offers an accessible and engaging learning environment for novice learners. Our formative evaluation with students, teachers, and educational staff shows that StoryBlocks's tangible code blocks and programmable audio stories provide a foundation for mixed-ability groups to discuss and explore programming concepts."
38,"Koushik, V., & Kane, S. K. (2017, October). Tangibles+ Programming+ Audio Stories= Fun. In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility (pp. 341-342). ACM.","Koushik, V., & Kane, S. K. (2017, October).",Tangibles+ Programming+ Audio Stories= Fun. ,2017,In Proceedings of the 19th International ACM SIGACCESS Conference on Computers and Accessibility (pp. 341-342). ACM.,"TAN, DES, OUT","Block-based programming languages enable novice programmers, including children, to learn the basics of programming. However, most block-based programming languages are not accessible to blind and visually impaired users because they rely upon visual drag-and-drop interaction, and because they typically create visual output. To improve access to block-based programming languages, we introduce Story Blocks, a programming toolkit that uses tangible blocks to represent story components, and which produces output in the form of accessible audio stories and games. Story Blocks provides an introductory programming environment that can be enjoyed by people of all abilities.","While block-based programming languages offer manyopportunities for novice programmers, many of the features of these languages remain inaccessible. By combining tangible input with engaging audio output, Story Blocks may offer a compelling approach to introducing programming concepts to students with avariety of abilities."
39,"Armaly, A., Rodeghero, P., & McMillan, C. (2017). A comparison of program comprehension strategies by blind and sighted programmers. IEEE Transactions on Software Engineering, 44(8), 712-724.","Armaly, A., Rodeghero, P., & McMillan, C. ",A comparison of program comprehension strategies by blind and sighted programmers. ,2017,"IEEE Transactions on Software Engineering, 44(8), 712-724.","CC, SR, TBP(JAVA), SM, PRF, FUN","Programmers who are blind use a screen reader to speak source code one word at a time, as though the code were text. This process of reading is in stark contrast to sighted programmers, who skim source code rapidly with their eyes. At present, it is not known whether the difference in these processes has effects on the program comprehension gained from reading code. These effectsare important because they could reduce both the usefulness of accessibility tools and the generalizability of software engineering studies to persons with low vision. In this paper, we present an empirical study comparing the program comprehension of blind and sighted programmers. We found that both blind and sighted programmers prioritize reading method signatures over other areas of code. Both groups obtained an equal and high degree of comprehension, despite the different reading processes.","Our conclusion is that blind and sighted programmers comprehend code in similar ways and that both groups are equally capable of producing coherent summaries of that code. We have presented a cursor-tracking study of blind programmers during source code summarization aimed at determining whether blind and sighted programmers focus on the same parts of a method when attempting to comprehend it. We compared our results to a previously conducted eye-tracking study of sighted programmers through both quantitative and qualitative analyses. We found that the blind and sighted groups both spent more time reading method signatures than other parts of the code. This underscores the previously-established importance of coherent method signatures to code comprehension. We also found that bothblind and sighted programmers spent less time on control flow than other code areas. The only difference that we found between the two groups is that blind programmers spent less time reading method invocations than did the sighted programmers.Our results suggest that blind programmers read andcomprehend code much like their sighted counterparts.Tools and techniques to speed up code comprehension on the part of sighted programmers are likely to be equally applicable to blind programmers provided any user interfaces are accessible to screen readers. Blind programmers can produce summaries that are as useful as those produced by sighted programmers, ignoring factors such as familiarity with the problem domain or third-party libraries. We hope that this study along with other relevant research will demonstrate to potential employers that blind programmers can be easily integrated into the workplace in much the sameway as sighted programmers. The blind group examined certain lines more closely than others because of the complexity of those lines as well as the complexity of the resulting syntax. This suggests that certain programming languages and coding styles are less suited for introducing blind students to programmingbecause the syntax creates an otherwise-avoidable distraction. C-family languages such as Java make extensive use of parentheses and semicolons which are always spoken by the screen reader and sound unnatural to the blind novice. Variable naming conventions such as Hungarian notation or separating words with underscores can complicate matters further. Languages such as Python whose syntax is more natural-sounding are likely to present lower barriers to entry for the blind. The Camel Case naming convention also presents a lower barrier to entry because most screen readers intelligently separate the words in a Camel Case variable name. Note that these observations are specifically aimed at lowering the barrier to entry for the blind into computer science. Blind programmers are as capable as sighted programmers of adapting to a variety of syntax variations and naming conventions once they are familiar withthe concepts involved in programming. Reducing the bar-riers of entry for the blind will yield more particiapnts foraccessibility studies. Some may even choose to researchtopics in accessibility that are informed by their experience using available accessibility tools. One area of future research is to further explore the impacts of syntax. If the ease with which blind novice programmers acclimate to different language syntax families can be quantified it would provide further guidance on thebest way to increase the participation of the blind in computer science. Moreover our finding that blind pro-grammers tend to break down complex lines of code intowords for greater clarity suggests that read counts and eye fixations correlate to the cyclomatic complexity of a given method. Another area of future research is to explore the effectiveness of alternative representations of code such as call graphs. If call graphs could be made accessible to the blind and their effectiveness as a code comprehension aid could be quantified it would further illuminate the similarities or differences in the way blind and sighted programmers mentally model a piece of code. Finally, we did not address the impact of other reading methods such as a braille display on code comprehension. A braille display shows a line of braille using metal pins ranging in width from twelve to eighty characters. Users can use a braille display in conjunction with speech output or as an alternative when it is necessary to mute the screen reader. Braille displays are expensive and uncommon except in Europe andother places where the government will subsidize the cost."
40,"Villar, N., Morrison, C., Cletheroe, D., Regan, T., Thieme, A., & Saul, G. (2019, April). Physical Programming for Blind and Low Vision Children at Scale. In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (p. INT003). ACM.","Villar, N., Morrison, C., Cletheroe, D., Regan, T., Thieme, A., & Saul, G.",Physical Programming for Blind and Low Vision Children at Scale. ,2019,In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (p. INT003). ACM.,"(Repititive should be removed)TAN, DES, OUT, PE, CD, CC","There is a dearth of appropriate tools for young learners with mixed visual abilities to engage withcomputational learning. Addressing this gap, we present Project Torino, a physical programming language for teaching computational learning to children ages 7-11 regardless of level of vision. To create code, children connect and manipulate tactile objects to create music, audio stories, or poetry. Designed to be made and deployed at scale, Project Torino (along with a scheme of work) has been successfully used by 30 non-specialist teachers with 75 children across the UK over three months.",
41,"Stefik, A., Alexander, R., Patterson, R., & Brown, J. (2007, June). WAD: A feasibility study using the wicked audio debugger. In 15th IEEE International Conference on Program Comprehension (ICPC'07) (pp. 69-80). IEEE.","Stefik, A., Alexander, R., Patterson, R., & Brown, J.", WAD: A feasibility study using the wicked audio debugger.,2007, In 15th IEEE International Conference on Program Comprehension (ICPC'07) (pp. 69-80). IEEE.,"TL, TBP,  CD, IDE, CC, ACUE, SPCH, PE, SM, COL","Contemporary programmers have a predominately visual experience. Computer code is read from sophisticated text editors, analyzed using visual tools, designed using UML, and debugged using a watch window. Little research has attempted to create tools for the non sighted programmer, using either haptic or aural feedback. In this paper, we present WAD, the Wicked Audio Debugger, a new debugger for Microsoft Visual Studio 2005 that sonifies computer code as an aid to the programmer. This paper has two primary contributions, namely the tool itself and the results of a feasibility study. We conducted this feasibility study to test participantsability to comprehend dynamic program behavior, including tracking the value of state variables and control flow. Results of our feasibility study show that participants were able to comprehend approximately 86% of dynamic program behavior using audio only.","In this paper, we have contributed in two primary ways.First, we presented an architecture for a new form of debugger, a sonified debugger. We have been using this debugger to run rapid prototyping and piloting for the design of our auditory objects. Second, our current work in auditory display is based on using static analysis techniques to supplement text to speech based dynamic program comprehension tools. We found that participants in our study were able to comprehend approximately 86% of the computer code in our tasks using speech based audio stimulus. This result is very encouraging, as it implies that tools based on speechare an excellent choice for use in dynamic program comprehension. Results from our work has practical applications in debugging and may be used as an enabling technology for non-sighted users. This feasibility study is part of a larger set of experiments. We have finished piloting our speech based tools and are encouraged by the results. Next, we will begin collecting data on a series of alternative designs, including musical ones, alternative speech designs, designs based on non-English languages, and likely others. Once we complete a series of these feasibility studies, we will begin comparative studies with multiple groups using different auditory objects."
42,"Stefik, A., Haywood, A., Mansoor, S., Dunda, B., & Garcia, D. (2009, May). Sodbeans. In 2009 IEEE 17th International Conference on Program Comprehension (pp. 293-294). IEEE.","Stefik, A., Haywood, A., Mansoor, S., Dunda, B., & Garcia, D. ", Sodbeans. ,2009,In 2009 IEEE 17th International Conference on Program Comprehension (pp. 293-294). IEEE.,"CC, CD, TL, TBP, ACUE, IDE","Comprehending and debugging computer programs areinherently difficult tasks for sighted programmers. Thesetasks are even more difficult for non-sighted programmers, who rely on audio-based representations of programs. The state-of-the-art approach to building program execution and debugging environments for non-sighted programmers is to retrofit existing visual environments with screen readers. Because of intrinsic differences in the ways humans process auditory and visual information, we argue that these environments are insensitive to the needs of the blind community. We present an alternative: SODBeans (the Sonified Omniscient Debugger in Netbeans), a compiler, debugger, and accessibility architecture for Netbeans 6.5.",
43,"Roberts, D., & Weaver, K. (2011). Audio Aids in Source Code. Retrieved September, 19, 2017.","Roberts, D., & Weaver, K.",Audio Aids in Source Code.,2011,"Retrieved September, 19, 2017.","ACUE, CC, CN, SR, TBP","Source code makes use of a number of visual cues to convey information to the reader. Things such ascapitalization, multicolor highlighting, and white space all have tremendous value when navigating code.These cues are not accessible to the visually impaired however, and most blind or visually impairedprogrammers have had to make do with simple text to speech software translations of the files they wishto read. This is not ideal, as it is difficult to ascertain certain things (present level of nesting for example)about a large source file without these visual delimiters. This research seeks to determine how establishedauditory cues can be used to augment the default output of text to speech software to aid the blind andvisually impaired with navigation and orientation within source files. Our preliminary findings suggestthat spearcons and white noise could be effective tools for indicating and distinguishing between discreteblocks of code.","This research has verified the effectiveness of the use of spearcons to enhance comprehension of sourcecode by visually impaired individuals. It has further suggested the direction that should be taken in thefuture to further refine the output of a custom screen-reader. While this project focused on proof of concept by generating audio files and testing their effectiveness,future research will seek to enhance the dynamic output of the screen reader itself by implementing theaudio cues presented here as a part of the screen reader. Additionally, the audio cues themselves may befurther refined, and a larger test group used to optimize the experience of visually impaired users."
44,"Kane, S. K., & Bigham, J. P. (2014, March). Tracking@ stemxcomet: teaching programming to blind students via 3D printing, crisis management, and twitter. In Proceedings of the 45th ACM technical symposium on Computer science education (pp. 247-252). ACM.","Kane, S. K., & Bigham, J. P. ","Tracking@ stemxcomet: teaching programming to blind students via 3D printing, crisis management, and twitter. ",2014, In Proceedings of the 45th ACM technical symposium on Computer science education (pp. 247-252). ACM.,"TAN, OUT","Introductory programming activities for students often include graphical user interfaces or other visual media that are inaccessible to students with visual impairments. Digital fabrication techniques such as 3D printing offer an opportunity for students to write programs that produce tactile objects, providing an accessible way of exploring program output. This paper describes the planning and execution of a four-day computer science education workshop in which blind and visually impaired students wrote Ruby programs to analyze data from Twitter regarding a fictional ecological crisis. Students then wrote code to produce accessible tactile visualizations of that data. This paper describes outcomes from our workshop and suggests future directions for integrating data analysis and 3D printing into programming instruction for blind students.","Learning to program still presents many accessibility challenges for blind and visually impaired people. One major opportunity is to identify introductory programming experiences that are compelling to novice programmers, but that are also accessible to programmers with varied abilities. We argue that combining data analysis tools with visualization tools, and with the fabrication of tactile graphic-based visualizations, presents an ideal environmentto teach programming to blind students. Our results from a four-day workshop show that blind students were motivated to learn about 3D printing technologies, and to use their programming skills to create 3D-printed artifacts. We also found that Ruby and its interactive interpreter offer a sufficient, if not perfect, environment for teaching blind students to program. We hope that this work will motivate the development of software tools and curricula to support blind programming students in the process of exploring, analyzing, andvisualizing data."
45,"Konecki, M., Lovren, A., & Kudeli, R. (2011, May). Making programming accessible to the blinds. In 2011 Proceedings of the 34th International Convention MIPRO (pp. 820-824). IEEE.","Konecki, M., Lovren, A., & Kudeli, R. ",Making programming accessible to the blinds. ,2011,In 2011 Proceedings of the 34th International Convention MIPRO (pp. 820-824). IEEE.,"CH,TBP, IDE, GUI (Not so relevant)","Development of graphical interfaces and visual programming concepts has created serious problems for the blinds regarding usage of computers and visualization. While this problem is still not so big regarding everyday computer usage it has become a major problem for blind programmers. In this paper we give an overview of major problems for the blinds regarding visual programming, we describe present efforts to make graphical interfaces more accessible to the blinds and we point out the concepts and tools that have been developed for blind programmers education and everyday work. We also show what present solutions lack and give possible solutions for resolution of this problem. Finally, we give an overview of our findings about what solution would be the most logical choice and we give a description of this solutions concepts. ","Rapid development of GUI and programming toolshas left blinds in rather difficult position. The interest forprogramming by the blinds community is still presentwhich can be seen by over 130 registered blindprogrammers with American Foundation of the blindprogrammers. There have been many different toolsdeveloped to aid blinds with computer usage based ontext-to-speech recognition. While these tools have beensufficient for textual programming and interface theyhave been insufficient regarding GUI development andprogramming. Many efforts have been made to try finding some method to bring visual information closer to blinds and enable them to perceive GUI in a more suitable way. None of them has however provided usable and generally acceptable solution for the blind programming professionals even though the results are promising in the way of promising future research.Several approaches could be taken in order to solvethese issues. These approaches include development ofmore sophisticated aiding tools, integration of aidingtools to programming environments or development ofspecial scripting languages for every particular versionand type of programming languages. In order to try toprovide a general solution a model of descriptionlanguage has been proposed that would enable user-friendly and extensible solution by usage of programminglanguage GUI generators. Detailed design anddevelopment of this solution will be included in ourfuture research."
46,"Konecki, M. (2012, May). A new approach towards visual programming for the blinds. In 2012 Proceedings of the 35th International Convention MIPRO (pp. 935-940). IEEE.","Konecki, M. ",A new approach towards visual programming for the blinds. ,2012,In 2012 Proceedings of the 35th International Convention MIPRO (pp. 935-940). IEEE.,"GUI, CH, AT, IDE","Visual user interfaces have left blind programmers that were able to perform programming job for years in a challenging situation. This problem has especially been present in classical desktop programming due to the nature of technology used in this field. Efforts have been made to help blinds work with graphical interfaces but none of them gave a fully usable solution for blind programming professionals. To solve this issue several different approaches can be applied but only one of them can lead to generally usable solution. In this paper mentioned approaches are discussed and proposed solution is described in more detail in the form of GUIDL (Graphical User Interface Description Language) that represents a new system that would include a new description language and would enable blinds to make graphical interfaces as a part of their programs in a way that would be acceptable to not only professional programmers but also to designers and other blind computer hobbyists. The demands for this kind of system as a combination of initial ideas and results obtained by research among the blind programmers will also be presented. Finally, a formal description of proposed system and its parts including a description language as its core part will be given.","Blinds have been using computers since the verybeginning of computer era. They have performedprogramming jobs with great success using various aiding technologies available. Since Graphic User Interface GUI development took place blind programmers have found themselves in difficult position particularly regarding development of Graphic User Interface GUI. Existing aiding tools were not able to support different Graphic User Interface GUI development environments in a way that would be generally usable to blind programmers andexisting efforts didnt give conclusive results. In order to solve this problem several approaches can be undertaken which include development of more sophisticated aiding tools, integration of different aiding technology to development environments and development of programming language specific scripting languages. In order to provide a generally usable solution a new model of GUIDL Graphic User Interface description language and system has been proposed based on defined requirements obtained by research that would provide simple and extensible solution for development of Graphic User Interface GUI. Testing and improving of GUIDL Graphic User Interface description language system will be a part of future research efforts."
47,"Wang, J., Chapati,  K.,  Ludi, S. 2017. An exploratory study into the use of auditory cues to sonify PencilCode programs, Denton,Texas, USA.","Wang, J., Chapati,  K.,  Ludi, S. ",An exploratory study into the use of auditory cues to sonify PencilCode programs. ,2017,,"BBL, ACUES, SR, OUT, CN, SPCH,CTRL, FUN","Visual programming languages are commonly used to help novice programmers learn introductory computer science. [3] This exploratory study investigates the effectiveness of different auditory cues in order to eventually make visual programming languages accessible to blind or visually-impaired individuals, who currently struggle to use a computer, let alone program on one. As blind individuals use screen readers to sonify text on their computer screens and previously have been known to be able to use visual programming languages [3], we investigated how to build upon existing screen reader capabilities to sonify the Pencil Code block-based visual programming language [2], as well as the auditory cue that most effectively conveys information to novice programmers. Our trials found all three auditory cues to be equally effective, but earcons were the most preferable and spearcons the least. Since preferences of auditory cues varied, the promising results of our study point to future coexistence of the three auditory cues. ","Our prototype demonstrates potential through its promising results: all of our participants were able to identify blocks through all three auditory cues. Although there is still progress to be made to improve overall program function discernibility, these auditory cues have been shown to be very effective after programmers overcome the initial learning curve. At first, visual programming languages seemed exclusive to sighted programmers, but through the results of this experiment, they have been shown to be extendable to blind or visually-impaired programmers through accessibility features, namely auditory cues. Specifically, earcons are both enjoyed and convey information intuitively, but have a slightly larger learning curve than the other two auditory cues. On the other hand, spearcons were not considered as useful or pleasant as the other two cues because of interference and slowness, but they were equally as effective as speech per the time it took to solve the spearcons programs. Since participants tended to have their own preferences of the best auditory cue and were generally able to use all three auditory cues successfully, future studies may involve the coexistence of all three auditory cues so that the user may choose their preferred auditory cue for sonification purposes.The results of our research may be taken as a guide for future experiments, as this has been our team's first set of trials. The problems we learned about in our prototype and the suggestions we received from our participants are the leverage we are using to take our design to the next level. In the future, further developments of these auditory cues can be applied to the actual Pencil Code visual programming language, allowing for us to bring visual programming languages to blind and visually-impaired programmers. Our more immediate future goal is to implement more intuitive and understandable auditory cues, especially spearcons with the screen readers. Previously, only sighted programmers could take advantage of the powerful pedagogical potential that visual programming languages offer. With the advancement of these auditory cues, they can later be implemented into Pencil Code so that blind and visually-impaired individuals are afforded the same educational tools with which sighted programmers facilitate their advancement of knowledge."
48,"Ludi,S., Adams,G., Blankenship, B., & Dapiran, M. (2011). The architectural challenges of adding accessibility features to ALICE as a case study of maintenance in educational software. In Proceedings of the 1st International Workshop on Games and Software Engineering (GAS 11). Association for Computing Machinery, New York, NY, USA, 33_35. DOI:https://doi.org/10.1145/1984674.1984686","Ludi,S., Adams,G., Blankenship, B., & Dapiran, M. ",The architectural challenges of adding accessibility features to ALICE as a case study of maintenance in educational software.,2011, In Proceedings of the 1st International Workshop on Games and Software Engineering (GAS 11). ACM,"DES, KN, BBL, CH","Games take many forms, including educational environments. Alice is an example of an engaging environment that teaches object-oriented programming through the development of animations. The AliceVI project sought to extent Alice to visually impaired users. This paper describes how the architectural of Alice impacted the ability to add accessibility features. The result has been to start a system, named BridgIT, from scratch. The technology and proposed architecture is discussed for the new system, which takes the tenets of Alice to a new group of users.",
49," Armaly, A.,  Rodeghero, P. , & McMillan, C. (2018) AudioHighlight: Code Skimming for Blind Programmers.  IEEE International Conference on Software Maintenance and Evolution (ICSME), Madrid, 2018, pp. 206-216."," Armaly, A.,  Rodeghero, P. , & McMillan, C.",AudioHighlight: Code Skimming for Blind Programmers.  ,2018,"IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 206-216.","IDE, CN, FUN, CTRL, CC, SR, SM, PRF, TBP","Blind programmers use a screen reader to read code aloud. Screen readers force blind programmers to read code sequentially one line at a time. In contrast, sighted programmers are able to skim visually to the most important code areas, assisted by syntax highlighting. However, there is a place where there is a widely adopted approach to skimming a structured document: the web. Modern screen readers employ what is known as a virtual cursor to navigate structural information on webpages such as HTML heading tags. These tags can indicate different sections and subsections in the structure of a page. We harness the existing familiarity of blind computer users with this interface in our approach which we call AudioHighlight. AudioHighlight renders the code inside a web view, either as part of the Eclipse IDE or as a web service. It places HTML heading tags on the structural elements of a source file such as classes, functions and control flow statements. We compare AudioHighlight to the state of the art in code skimming represented by a previous code skimming approach called StructJumper. We also compare to the state of practice in reading code on the web as represented by GitHub. We found that AudioHighlight increased the quality and speed of code comprehension as compared to both approaches.","We have presented AudioHighlight, a code skimming approach for blind programmers. AudioHighlight leverages the existing familiarity of blind computer users with skimming documents on the web by presenting code in a web view. Classes, functions and other block statements are marked up using HTML headings. We have made AudioHighlight usable on the web through the AudioHighlight service. WE have also made AudioHighlight usable from within the Eclipse IDE through the AudioHighlight Eclipse plugin. We conducted three evaluations of AudioHighlight. The first two compared AudioHighlight to StructJumper, the state of the art in code skimming for the blind. The third evaluation compared AudioHighlight to GitHub which represents the state of practice for the blind in reading code on the web. Evaluation 1 replicated the StructJumper evaluation which asked participants to find specific locations in code. evaluation 2 and Evaluation 3 asked the participants to summarize Java classes using AudioHighlight and either StructJumper or GitHub. Our evaluations found that participants took less time to complete a task using AudioHighlight. Participants performed better or equally when using AudioHighlight as compared to StructJumper and GitHub. Finally, participants perceived the tasks to be easier when using AudioHighlight. We hope that AudioHighlight increases the productivity of blind programmers by allowing them to better skim a piece of code. Our sincere hope is that vendors of IDEs and websites that host code adopt the AudioHighlight approach so that blind programmers are able to skim the code that they present on their site to increase accessibility."
50,"Falase, O., Siu, A.F., & Follmer, S. (2019). Tactile Code Skimmer: A Tool to Help Blind Programmers Feel the Structure of Code. ASSETS '19.","Falase, O., Siu, A.F., & Follmer, S. ",Tactile Code Skimmer: A Tool to Help Blind Programmers Feel the Structure of Code,2019,ASSETS '19.,"CN, TBP, CC, SR, TL, DES, TAN","Skimming new code with a screen reader can be a timeconsuming task for blind and visually impaired programmers. Screen readers aid with code navigation, but dictate code line-by-line and read spaces and tabs individually. This often provides more information than is needed. In this work, we present the Tactile Code Skimmer (TCS), a tool to aid blind and visually impaired programmers with skimming code. The device physically reflects the indentation levels of code with actuated slide potentiometers, thus helping reduce the ""hearing load"" that often accompanies screen readers. We describe the TCS design and implementation. Based on feedback from participants obtained through demos and an in-depth session, we discuss some considerations for tactile tools that aid with code skimming.","We have presented TCS, a tactile tool to help blind and visually impaired (BVI) programmers navigate new code and understand its structure. We propose that such a tool could help offload the memorization that often accompanies understanding new code as a BVI programmer, as well as the ""hearing load"" from screen readers. Feedback from an informal user study and suggestions for improvements on such a tactile device offer considerations for future tactile code skimming tools."